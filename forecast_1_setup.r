# This script generates a dataframe containing the information needed for subsequent analysis and saves it as out_path/project_var.csv
# The dataframe contains the following columns:
# project: project ID
# country: project country
# t0: project start year
# area_ha: project area in hectares
# cdens_1 to cdens_6: reference carbon density (MgC ha-1) per land class
# n_1 to n_6: number of GEDI beams used to calculate reference carbon density per land class
# se_1 to se_6: standard error of reference carbon density per land class

# It requires the following inputs:
#1. analysis_type: "ongoing" for ongoing projects; "placebo" for placebo projects
#2. project_dir: absolute path of the directory containing implementation output
#3. polygon_dir: absolute path of the directory containing project shapefiles
#2. out_path: absolute path (plus prefix) of files generated by this repo
#5. proj_info: data frame containing project ID, country and start year (dependent on analysis_type)
#6. include_strings: vector containing strings to include when searching for directories containing implementation output (dependent on analysis_type)
#7. exclude_strings: vector containing strings to exclude when searching for directories containing implementation output (dependent on analysis_type)

rm(list = ls())

#Load packages
library(tidyverse) #stringr::str_subset used in FindFiles.r, dplyr used throughout, tibble to store labels with bquote()
library(magrittr) #pipe operators
library(units) #set_units()
library(sf) #st_drop_geometry() (runs on GDAL 3.10)
library(arrow) #read_parquet()

#Load pre-defined functions
source("FindFiles.r") #wrapper function to search files or folders based on inclusion/exclusion keywords

#Define input variables
analysis_type = "ongoing" #analysis type
project_dir = "/maps/epr26/tmf_pipe_out/" #path to directories containing implementation outputs
polygon_dir = "/maps/epr26/tmf-data/projects/" #path to polygons
cdens_dir = "/maps/epr26/tmf_pipe_out/cdens_new/" #path to newly generated carbon density tables with SE

out_path = paste0("/maps/epr26/ex_ante_forecast_out/out_", analysis_type) #path to store script output

if(analysis_type == "ongoing") {
  #load basic information (csv file copied from Tom's directory)
  proj_info = read.csv("proj_meta.csv") %>%
    dplyr::select(ID, COUNTRY, t0) %>%
    rename(project = ID, country = COUNTRY)

  #standardise country names: Lao => Lao PDR, Congo, Dem Rep of the => Congo, Dem. Rep.
  proj_info$country[proj_info$country == "Lao"] = "Lao PDR"
  proj_info$country[proj_info$country == "Congo, Dem Rep of the"] = "Congo, Dem. Rep."

  #define include and exclude strings
  include_strings = NULL
  exclude_strings = c("archive", "slopes", "elevation", "srtm", "asn", "af", "sa", "\\.", "\\_")

} else if(analysis_type == "placebo") {
  #load basic information
  proj_info = read.csv("proj_meta_placebo.csv") %>%
    dplyr::select(ID, COUNTRY, t0) %>%
    rename(project = ID, country = COUNTRY)

  #define include and exclude strings
  include_strings = c("asn", "af", "sa")
  exclude_strings = "\\."
}

#Find directories containing implementation outputs and save project names in vector "projects"
projects = FindFiles(project_dir, include = include_strings, exclude = exclude_strings)

#Sort by project ID
if(analysis_type == "ongoing") {
  projects = projects %>%
    as.numeric() %>%
    sort()
} else {
  projects = projects %>%
    sort()
}

#Retrieve data frames containing carbon density (MgC/ha) per LUC
cdens_list = vector("list", length(projects))
for(i in seq_along(projects)) {
  cdens_path = FindFiles(cdens_dir, paste0(projects[i], "_carbon_density"), full = T)
  if(!is.na(cdens_path)) {
    cdens = read.csv(cdens_path)
    colnames(cdens) = c("luc", "cdens", "n", "se")
    for(class in 1:6) {
      if(class %in% cdens$luc == F) cdens = rbind(cdens, c(class, NA, NA, NA))
    }
    cdens = cdens %>%
      arrange(luc) %>% #order land class from 1 to 6
      mutate(project = projects[i])
    cdens_list[[i]] = cdens
  }
}
names(cdens_list) = projects

#Check if carbon density values for LUC 1, 2, 3, and 4 are available
is_carbon_complete = sapply(cdens_list, function(x) !is.na(sum(x[1:4, ]$cdens)))

#Check if pairs parquet files are present (indicating complete output)
is_done = sapply(projects, function(x) FindFiles(paste0(project_dir, x, "/pairs"), ".parquet") %>% length() == 200)

#Select projects with complete output
projects_status = data.frame(project = projects, carbon_complete = is_carbon_complete, done = is_done)
projects = subset(projects_status, carbon_complete & done)$project

#Retrieve project variables
project_var = proj_info[match(projects, proj_info$project), ]

#Retrieve project areas (ha)
polygon_paths = paste0(polygon_dir, projects, ".geojson")
project_var$area_ha = sapply(seq_along(projects), function(i) {
  area_ha_i = st_read(polygon_paths[i]) %>%
    st_make_valid() %>%
    st_union() %>%
    st_transform(4326) %>%
    st_area() %>% #area in m^2
    set_units(ha) #convert into hectares
  return(area_ha_i)
})

#Retrieve carbon density
cdens_df = lapply(cdens_list, function(x) {
  if(!is.null(x)) {
    x = x %>%
      filter(luc %in% 1:6) %>%
      pivot_wider(names_from = luc, values_from = cdens:se)
  } else {
    x = NULL
  }
  }) %>%
  list_rbind()
project_var = merge(project_var, cdens_df, by.x = "project", by.y = "project", all.x = T)

#Retrieve project-level environmental characteristics
var_envir_list = vector("list", length(projects))
for(i in seq_along(projects)) {
  k_path = FindFiles(paste0(project_dir, projects[i]), "k.parquet", full = T)
  m_path = FindFiles(paste0(project_dir, projects[i]), "matches.parquet", full = T)

  setK = read_parquet(k_path)
  setM = read_parquet(m_path)
  var_envir_list[[i]] = data.frame(prj_elev = mean(setK$elevation, na.rm = T),
                                   prj_slope = mean(setK$slope, na.rm = T),
                                   prj_remote = mean(setK$access, na.rm = T),
                                   reg_elev = mean(setM$elevation, na.rm = T),
                                   reg_slope = mean(setM$slope, na.rm = T),
                                   reg_remote = mean(setM$access, na.rm = T))
}
var_envir = list_rbind(var_envir_list)
project_var = cbind(project_var, var_envir)

#load socio-economic variables for each country
#Average and annual compound growth rate of GDP per capita (US$) five years prior to project start
gdppc = read.csv("/maps/epr26/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_85121.csv", header = T, skip = 4) %>%
  dplyr::select(!c(2:4, "X")) %>%
  pivot_longer(cols = starts_with("X"), values_to = "value", names_to = "year", names_prefix = "X")

project_var$gdppc_mean = NA
project_var$gdppc_rate = NA
for(i in seq_along(project_var$project)) {
  country_i = project_var[i, ]$country
  t0_i = project_var[i, ]$t0
  gdppc_i = subset(gdppc, Country.Name == country_i & year <= t0_i & year >= t0_i - 5)
  gdppc_mean = mean(gdppc_i$value, na.rm = T)
  gdppc_rate = (gdppc_i[6, ]$value / gdppc_i[1, ]$value) ^ (1 / 5)
  project_var[i, ]$gdppc_mean = gdppc_mean
  project_var[i, ]$gdppc_rate = gdppc_rate
}

#Average and annual compound growth rate of  World Governance Index Control of Corruption indicator five years prior to project start
wgicc = read.csv("/maps/epr26/wgidataset.csv", header = T) %>%
  filter(indicator == "cc") %>%
  mutate(estimate = as.numeric(estimate))

project_var$wgicc_mean = NA
for(i in seq_along(project_var$project)) {
  country_i = project_var[i, ]$country
  t0_i = project_var[i, ]$t0
  wgicc_i = subset(wgicc, countryname == country_i & year <= t0_i & year >= t0_i - 5)
  project_var[i, ]$wgicc_mean = mean(wgicc_i$estimate, na.rm = T)
}

#Output
write.csv(projects_status, paste0(out_path, "_project_status.csv"), row.names = F) #project status check results
write.csv(project_var, paste0(out_path, "_project_var.csv"), row.names = F) #project-level variables