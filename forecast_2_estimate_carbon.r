# This script reads the k.parquet and matches.parquet files generated by the implementatio code for each project,
# retrieves and saves as csv files the following three time series for 100 subsampled pixel sets of each project:
# 1. Ex post additionality (additionality_[proj].csv)
# 2. Historical project carbon loss rate (project_closs_rate_[proj].csv)
# 3. Historical regional carbon loss rates (regional_closs_rate_[proj].csv)
# It then calculates and saves as csv files the bootstrapped mean over the 100 sets of each project:
# 1. Ex post additionality (boot_additionality_[proj].csv)
# 2. Historical project carbon loss rate (boot_project_closs_rate_[proj].csv)
# 3. Historical regional carbon loss rates (boot_regional_closs_rate_[proj].csv)

# The additionality_[proj].csv files contain the following columns:
# year: year
# pair: subsample ID
# counterfactual: carbon density in the counterfactual scenario at the given year (MgC ha-1)
# project: carbon density in the project area at the given year (MgC ha-1)
# diff_cf: counterfactual carbon loss from t0 to the given year (MgC ha-1)
# diff_p: project carbon loss from t0 to the given year (MgC ha-1)
# additionality_whole: carbon credits (additionality) from t0 to the given year (MgC ha-1 yr-1)
# additionality_annual: annual carbon credit generation rate (annual additionality) from t0 to the given year (MgC ha-1 yr-1)

# The project/regional_closs_rate_[proj].csv files contain the following columns:
# year: year
# pair: subsample ID
# counterfactual: carbon density in the counterfactual scenario at the given year (MgC ha-1)
# project: carbon density in the project area at the given year (MgC ha-1)
# closs: counterfactual carbon loss from the given year to t0 (MgC ha-1)
# closs_annual: annual compound carbon loss rate from the given year to t0 (MgC ha-1 yr-1)

# It requires the following input variables:
#1. parquet_path: absolute path of the directory containing implementation code output (k.parquet, matches.parquet) of each project
#2. out_path: absolute path (plus prefix) of files generated by this repo, including in forecast_1_setup.r

rm(list = ls())

#Load packages
library(tidyverse) #ggplot2, dplyr, and stringr used in plotPlacebo/plotBaseline.r: tibble to store labels with bquote()
library(magrittr) #pipe operators
library(sf) #st_drop_geometry() used in GetCarbonLoss.r (runs on GDAL 3.10)
library(arrow) #read_parquet()
library(MatchIt) #matchit(), used in the customised function AssessBalance()

#Load pre-defined functions
source("FindFiles.r") #wrapper function to search files or folders based on inclusion/exclusion keywords
source("ReformatPixels.r") #wrapper function to reformat column names of data frame of matched pixels
source("AssessBalance.r") #function to assess matching balance
source("GetCarbonLoss.r") #function to generate time series of annual change in project-level average carbon density
source("BootOut.r")

#Define input variables
parquet_path = "/maps/epr26/tmf_pipe_out/" #path to directories containing implementation outputs
out_path = "/maps/epr26/ex_ante_forecast_out/out_ongoing" #path of files generated by this repo, including in forecast_1_setup.r

project_var = read.csv(paste0(out_path, "_project_var.csv"), header = T)
projects = project_var$ID
t0_vec = project_var$t0
area_ha_vec = project_var$area_ha
cdens_list = project_var %>%
  dplyr::select(ID, cdens_1:cdens_6) %>%
  pivot_longer(cdens_1:cdens_6, names_to = "land.use.class", names_prefix = "cdens_", values_to = "carbon.density") %>%
  split(f = .$ID)

#Retrieve input paths needed for the analysis
parquet_dirs = paste0(parquet_path, projects)
k_paths = rep(NA, length(projects))
m_paths = rep(NA, length(projects))
for(i in seq_along(projects)) {
  k_paths[i] = FindFiles(parquet_dirs[i], "k.parquet", full = T)
  m_paths[i] = FindFiles(parquet_dirs[i], "matches.parquet", full = T)
}

# B. Get ex post additionality, project and regional carbon loss rates ----
for(i in seq_along(projects)) {
  t0 = t0_vec[i]
  luc_t_20 = paste0("luc_", t0_vec[i] - 20)
  luc_t_10 = paste0("luc_", t0_vec[i] - 10)
  luc_t0 = paste0("luc_", t0_vec[i])
  area_ha = area_ha_vec[i]
  cdens = cdens_list[[i]]
  pair_dir = paste0(parquet_dirs[i], "/pairs/")

  a = Sys.time()
  #find paths to match and unmatached points in each sampled pairs
  pair_paths = FindFiles(pair_dir, include = ".parquet", full = T)
  matched_paths = pair_paths %>% str_subset("matchless", negate = T)
  matchless_paths = pair_paths %>% str_subset("matchless")

  if(length(matched_paths) == 0) {
    cat("No matches\n")
    closs_df = NULL
    expost_add = NULL
    closs_project = NULL
  } else {
    pairs_out = lapply(seq_along(matched_paths), function(j) {
      pair_start = Sys.time()

      matched_path = matched_paths[j]
      matchless_path = matchless_paths[j]

      pairs = read_parquet(matched_path) %>%
        dplyr::select(-dplyr::ends_with(c("_x", "_y", "_trt", "_cluster")))
      unmatched_pairs = read_parquet(matchless_path) %>%
        dplyr::select(-dplyr::ends_with(c("_x", "_y", "_trt", "_cluster")))

      #calculate proportion of unmatched pixels, used to adjust the area represented by sample: is this still necessary?
      area_adj_ratio = nrow(pairs) / (nrow(pairs) + nrow(unmatched_pairs))

      pixels_cf = ReformatPixels(in_df = pairs, prefix = "s_", t0 = t0, treatment = "counterfactual", pair = j)
      pixels_p = ReformatPixels(in_df = pairs, prefix = "k_", t0 = t0, treatment = "project", pair = j)
      pixels_matched = rbind(pixels_cf, pixels_p)

      #assess matching balance
      balance_assessment = AssessBalance(pixels_matched, t0 = t0)

      #retrieve carbon time series for project and matched counterfactual
      carbon_cf = GetCarbonLoss(pixels_cf, t0, area_ha, area_adj_ratio, cdens, pair = j)
      carbon_p = GetCarbonLoss(pixels_p, t0, area_ha, area_adj_ratio, cdens, pair = j)

      pair_end = Sys.time()
      cat(j, ":", pair_end - pair_start, "\n")

      return(list(carbon_cf = carbon_cf, carbon_p = carbon_p,
                  pixels_matched = pixels_matched, area_adj_ratio = area_adj_ratio,
                  balance_assessment = balance_assessment))
    })
  }

  b = Sys.time()
  cat("Project", i, "/", length(projects), "-", projects[i], "- project carbon loss :", b - a, "\n")

  a = Sys.time()
  setM = read_parquet(m_paths[i])
  if(nrow(setM) > 250000) setM = setM[sample(nrow(setM), 250000), ]
  pixels_region = ReformatPixels(in_df = setM, prefix = "", t0 = t0, treatment = "region", pair = 1)

  #retrieve carbon time series for surrounding region
  closs_region = GetCarbonLoss(pixels_region, t0, area_ha, area_adj_ratio = 1, cdens, pair = 1)
  b = Sys.time()
  cat("Project", i, "/", length(projects), "-", projects[i], "- regional carbon loss :", b - a, "\n")

  carbon_cf = lapply(pairs_out, function(x) x$carbon_cf) %>%
    list_rbind() %>%
    mutate(treatment = "counterfactual")

  carbon_p = lapply(pairs_out, function(x) x$carbon_p) %>%
    list_rbind() %>%
    mutate(treatment = "project")

  carbon_matched = rbind(carbon_cf, carbon_p) %>%
    pivot_wider(values_from = "carbon_density", names_from = "treatment")
  tmax = max(carbon_matched$year)

  #calculate ex post annual per-area additionality
  additionality = carbon_matched %>%
    filter(year >= t0) %>%
    group_by(pair) %>%
    mutate(diff_cf = first(counterfactual) - counterfactual,
           diff_p = first(project) - project,
           additionality_whole = diff_cf - diff_p,
           additionality_annual = exp(log(additionality_whole) / (year - t0)))

  #calculate ex ante within-project annual per-area carbon loss rates
  ante_project = carbon_matched %>%
    filter(year <= t0) %>%
    group_by(pair) %>%
    mutate(closs = project - last(project),
           closs_annual = exp(log(closs) / (t0 - year)))

  #calculate ex ante regional annual per-area carbon loss rates
  ante_region = closs_region %>%
    filter(year <= t0) %>%
    group_by(pair) %>%
    mutate(closs = carbon_density - last(carbon_density),
           closs_annual = exp(log(closs) / (t0 - year))) %>%
    mutate(closs_annual = ifelse(closs_annual >= 0, closs_annual, NA))

  write.csv(additionality, paste0(out_path, "_additionality_", projects[i], ".csv"), row.names = F)
  write.csv(ante_project, paste0(out_path, "_project_closs_rate_", projects[i], ".csv"), row.names = F)
  write.csv(ante_region, paste0(out_path, "_regional_closs_rate_", projects[i], ".csv"), row.names = F)
}


# C. Bootstrap outcomes ----
additionality_boot_list = vector("list", length(projects))
ante_project_boot_list = vector("list", length(projects))
ante_region_boot_list = vector("list", length(projects))

for(i in seq_along(projects)) {
  t0 = t0_vec[i]
  project_i = projects[i]
  additionality = read.csv(paste0(out_path, "_additionality_", projects[i], ".csv"), header = T)
  ante_project = read.csv(paste0(out_path, "_project_closs_rate_", projects[i], ".csv"), header = T)
  ante_region = read.csv(paste0(out_path, "_regional_closs_rate_", projects[i], ".csv"), header = T)
  tmax = max(additionality$year)

  #bootstrap ex post additionality
  a = Sys.time()
  additionality_boot_list[[i]] = BootOut(in_df = additionality, column = "additionality_annual", from = t0 + 1, to = tmax) %>%
    mutate(project = project_i)
  b = Sys.time()
  cat("Project", i, "/", length(projects), "-", projects[i], "- additionality bootstrapped:", b - a, "\n")

  #bootstrap ex ante project carbon loss rate
  a = Sys.time()
  ante_project_boot_list[[i]] = BootOut(in_df = ante_project, column = "closs_annual", from = t0 - 10, to = t0 - 1) %>%
    mutate(project = project_i)
  b = Sys.time()
  cat("Project", i, "/", length(projects), "-", projects[i], "- project rate bootstrapped:", b - a, "\n")

  #bootstrap ex ante regional carbon loss rate
  a = Sys.time()
  ante_region_boot_list[[i]] = BootOut(in_df = ante_region, column = "closs_annual", from = t0 - 10, to = t0 - 1) %>%
    mutate(project = project_i)
  b = Sys.time()
  cat("Project", i, "/", length(projects), "-", projects[i], "- project rate bootstrapped:", b - a, "\n")
}

additionality_boot_df = list_rbind(additionality_boot_list)
ante_project_boot_df = list_rbind(ante_project_boot_list)
ante_region_boot_df = list_rbind(ante_region_boot_list)

write.csv(additionality_boot_df, paste0(out_path, "_boot_additionality.csv"), row.names = F)
write.csv(ante_project_boot_df, paste0(out_path, "_boot_project_closs_rate.csv"), row.names = F)
write.csv(ante_region_boot_df, paste0(out_path, "_boot_regional_closs_rate.csv"), row.names = F)